using HDF5 
using Printf
using LinearAlgebra
using DataFrames
import Random, Distributions

using VQE
using Zygote
using PyPlot
using Parameters
using NLopt
using DocStringExtensions
using OrdinaryDiffEq
#using Yao
using YaoBlocks, ChainRulesCore



function expand_blocks_v2(arr::Vector{T}, n::Int) where T
    # Compute block size dynamically
    block_len = n + 3  # Each block has (N + 3) elements
    p = length(arr) รท block_len  # Number of layers

    # Expanded block size (2 extra elements per layer)
    new_block_len = block_len + 2  
    new_len = p * new_block_len  # Compute the new array size
    new_arr = Vector{T}(undef, new_len)  # Initialize expanded array

    # Track position in new_arr
    idx_new = 1

    for block_idx in 0:(p-1)
        # Identify the sub-block in arr
        start_idx = block_idx * block_len + 1
        stop_idx  = start_idx + block_len - 1
        block = arr[start_idx : stop_idx]  # Extract current block

        # Last element remains unchanged
        last_element = block[end]

        # Determine insertion points dynamically
        partition_size = div(block_len - 1, 2)  # First (N+2)/2 elements
        first_insert_pos = partition_size  # First half insertion index
        second_insert_pos = 2 * partition_size  # Second half insertion index

        # First half
        first_half = block[1:first_insert_pos]
        insert!(first_half, first_insert_pos + 1, first_half[end])  # Copy of last element in this half
        first_half[first_insert_pos] = first_half[first_insert_pos - 1]  # Copy previous element

        # Second half
        second_half = block[first_insert_pos+1:second_insert_pos]
        insert!(second_half, first_insert_pos + 1, second_half[end])  # Copy of last element in this half
        second_half[first_insert_pos] = second_half[first_insert_pos - 1]  # Copy previous element

        # Copy to new array
        for val in first_half
            new_arr[idx_new] = val
            idx_new += 1
        end
        for val in second_half
            new_arr[idx_new] = val
            idx_new += 1
        end
        new_arr[idx_new] = last_element # Copy the last element
        idx_new += 1
    end

    return new_arr
end

function reduce_blocks_v2(arr::Vector{T}, n::Int) where T
    # Compute block size dynamically
    block_len = n + 2 + 3  # Each block has (N + 3) elements
    p = length(arr) รท block_len  # Number of layers

    # Expanded block size (2 less elements per layer)
    new_block_len = block_len - 2  
    new_len = p * new_block_len  # Compute the new array size
    new_arr = Vector{T}(undef, new_len)  # Initialize expanded array

    # Track position in new_arr
    idx_new = 1

    for block_idx in 0:(p-1)
        # Identify the sub-block in arr
        start_idx = block_idx * block_len + 1
        stop_idx  = start_idx + block_len - 1
        block = arr[start_idx : stop_idx]  # Extract current block

        # Last element remains unchanged
        last_element = block[end]

        # Determine insertion points dynamically
        partition_size = div(block_len - 1, 2)  # First (N+2)/2 elements
        first_insert_pos = partition_size  # First half insertion index
        second_insert_pos = 2 * partition_size  # Second half insertion index

        # First half: remove the 1 inserted elements
        first_half = block[1:first_insert_pos-2]
        first_half_last = block[first_insert_pos]
        insert!(first_half, first_insert_pos-1, first_half_last)  # Copy of last element in this half
        
        # Second half: remove the 1 inserted elements
        second_half = block[first_insert_pos+1:second_insert_pos-2]
        second_half_last = block[second_insert_pos]
        insert!(second_half, first_insert_pos-1, second_half_last)  # Copy of last element in this half
        
        # Last element stays the same
        last_element = block[end]

        # Combine and copy to reduced array
        for val in vcat(first_half, second_half, [last_element])
            new_arr[idx_new] = val
            idx_new += 1
        end
    end

    return new_arr
end

function expand_blocks_2(arr::Vector{T}, arr2::Vector{T}, n::Int) where T
    # Number of blocks
    block_len = 2n + 1
    p = length(arr) รท block_len

    # Prepare the result container (length p*(2n + 5))
    new_len = p * (2n + 5)
    new_arr = Vector{T}(undef, new_len)

    # We'll track position in new_arr as we go
    idx_new = 1

    for block_idx in 0:(p-1)
        # Identify the sub-block in arr
        start_idx = block_idx * block_len + 1
        stop_idx  = start_idx + block_len - 1
        block = arr[start_idx : stop_idx]  # length (2n+1)

        # 1) Copy elements 1..n
        for i in 1:n
            new_arr[idx_new] = block[i]
            idx_new += 1
        end

        # 2) Instead of inserting two copies of block[n],
        #    insert the two additional elements provided in arr2.
        new_arr[idx_new]   = arr2[1]
        new_arr[idx_new+1] = arr2[2]
        idx_new += 2

        # 3) Copy elements (n+1)..(2n)
        for i in (n+1):(2n)
            new_arr[idx_new] = block[i]
            idx_new += 1
        end

        # 4) Insert two copies of the (2n)-th element (unchanged)
        new_arr[idx_new]   = arr2[1]
        new_arr[idx_new+1] = arr2[2]
        idx_new += 2

        # 5) Finally, copy the last element (index 2n+1)
        new_arr[idx_new] = block[2n+1]
        idx_new += 1
    end

    return new_arr
end


function replace_blocks_v2(arr::Vector{T}, arr2::Vector{T}, n::Int) where T
    # Number of blocks
    block_len = n + 3
    p = length(arr) รท block_len

    # Prepare the result container (length p*(2n + 5))
    new_len = p * (n + 3)
    new_arr = Vector{T}(undef, new_len)

    # We'll track position in new_arr as we go
    idx_new = 1

    for block_idx in 0:(p-1)
        # Identify the sub-block in arr
        start_idx = block_idx * block_len + 1
        stop_idx  = start_idx + block_len - 1
        block = arr[start_idx : stop_idx]  # length (2n+1)

        # 1) Copy elements 1..n/2 - 1
        for i in 1:(Int(n/2) - 1)
            new_arr[idx_new] = block[i]
            idx_new += 1
        end

        # 2) Instead of inserting one copy of block[n],
        #    insert the one additional element provided in arr2.
        new_arr[idx_new]   = arr2[idx_new]
        new_arr[idx_new+1]   = arr2[idx_new+1]
        idx_new += 2

        # 3) Copy elements (n/2+2)..n
        for i in (Int(n/2)+2):n
            new_arr[idx_new] = block[i]
            idx_new += 1
        end

        # 4) Insert one copy of the (2n)-th element (unchanged)
        new_arr[idx_new]   = arr2[idx_new]
        new_arr[idx_new+1]   = arr2[idx_new+1]
        idx_new += 2

        # 5) Finally, copy the last element (index 2n+1)
        new_arr[idx_new] = block[n+3]
        idx_new += 1
    end

    return new_arr
end



# load the MAX2SAT instance data

N = 16
#N = parse(Int, ARGS[1])
num_clauses = 3N

p = 15

PATH = raw"/home/ubuntu/MAX2SAT/"


#subdir = "small_gaps"
# subdir = "large_gaps"

# permutation data
#folder_name = PATH * @sprintf("//MAX2SAT_transformation_instances//N_%i//", N);

# transformed data
folder_name = PATH * @sprintf("//MAX2SAT_transformation_instances//trans_test//N_%i//", N);


### change N in the pattern individually 
pattern = r"transformed_MAX2SAT_instance_N_16_idx_(\d{4})\.h5"

###

instance_names = readdir(folder_name)
loop_var = 1
#loop_var = parse(Int, ARGS[2])
total_num_inst = 0

for (k, instance_name) in enumerate(instance_names[loop_var+200:loop_var+298])

    global total_num_inst = k
    println("current instance count: ", k)

    idx = match(pattern, instance_name)[1]
    idx = parse(Int64, idx)
    println("idx: ", idx)

    file_name = folder_name * @sprintf("transformed_MAX2SAT_instance_N_%i_idx_%04i.h5", N , idx)

    gs_energy = h5read(file_name, "ground_state_energy") 
    J_mat = h5read(file_name, "couplings"); 
    local_fields = h5read(file_name, "local_fields")
    mf_problem = Problem(0, - local_fields, J_mat);
    println(gs_energy)


    MAX_problem = Problem(p, - local_fields, J_mat) # minus sign added to local fields for MAX2SAT


    num_params = (N+3)*p

    # N16 0.001
    global learning_rate = 0.001 #N14 0.005   
    niter = 100

    global best_cost = 0
    global best_params = zeros(num_params)
    global best_initial_params = zeros(num_params)
    global best_lr = learning_rate
    global best_probs = zeros(Float64, 2^N)
    global _params = zeros(num_params)

    # partly optimized N 14
    #global best_initial_params = [0.6220815844218651, 0.5074299332413689, 0.5043683661182548, 0.49833971476266997, 0.510276914590918, 0.5206618481136615, 0.49757826471496025, 0.30653397690456174, 0.7297506295350711, 0.4019230939082597, 0.40005357543076053, 0.394323600192606, 0.4065636222399101, 0.39863791889482053, 0.5009165590556397, 0.7604219629810537, 0.19197236573785406, 0.5642210190079168, 0.5146990586350477, 0.5100634453375217, 0.5079724221371014, 0.5213059927782332, 0.5341314691867802, 0.47675003527578835, 0.09683176091142082, 0.6371003796698035, 0.3667441475311086, 0.36903414309985755, 0.36620426588215405, 0.36559063901636013, 0.35198031860648604, 0.42855210399919413, 0.6828489425207696, 0.04057928332953765, 0.48622606001214264, 0.4901828791575302, 0.4957628417227419, 0.49083052765743157, 0.5034549719440377, 0.5092834284392462, 0.4480333758574124, 0.21999091499128764, 0.646349850250317, 0.36462528312560033, 0.36861915265885165, 0.36406137501143115, 0.35726763781652937, 0.34952502834387, 0.3994587733312763, 0.672511726606799, 0.2476704692153762, 0.43891428269000704, 0.473355841903143, 0.48877122603086076, 0.4807146062323304, 0.4816065337502712, 0.4811802113845635, 0.44008740789584033, 0.38326120479307346, 0.6341555407802257, 0.3889473048521571, 0.3893005009189968, 0.38417147102916255, 0.3768816276271518, 0.3830375722357212, 0.41517449668374873, 0.7442627122459592, 0.26940309553955083, 0.41969252056488926, 0.46988797141384514, 0.4838976591662027, 0.4795025353324528, 0.46685291909936616, 0.4670794526302917, 0.4617968438598363, 0.5058269541526184, 0.553008340733257, 0.4187009144354, 0.4138703659839627, 0.41186047009494553, 0.40573176528037835, 0.42169803131062555, 0.43404576481595347, 0.6313100454290204, 0.31480123084361983, 0.427533114594724, 0.468003036016791, 0.4808077690026385, 0.47746226091976446, 0.45862085291814475, 0.46666764260770316, 0.4879527631138071, 0.49029876960517654, 0.4799374751269165, 0.44027119222857375, 0.4329224591212817, 0.4362612953531481, 0.4317137621446909, 0.44835321457021343, 0.43913068425404, 0.5516530559398339, 0.3535718355286839, 0.4435859999581874, 0.46667613925908813, 0.4814236631565478, 0.4693023473020668, 0.45626520292785705, 0.47050204135434615, 0.4970796947765405, 0.48591506996205075, 0.4408574998763726, 0.44856467816335105, 0.44242847317929146, 0.451930216305916, 0.44897535943583483, 0.45773191322969303, 0.4394070549550817, 0.4930286626193822, 0.35692916680978226, 0.45645143889068157, 0.46721438631782974, 0.4784993767658728, 0.45702182216786064, 0.45521918932319727, 0.46530261811701285, 0.4873109174732873, 0.4866891091141015, 0.4294545727919972, 0.4453710382258715, 0.44534435642642284, 0.45827602527493183, 0.45790257408577406, 0.4583917194195284, 0.4422010816651988, 0.4651894807571494, 0.368286462030672, 0.45644322736454035, 0.46731510230573803, 0.4712762664531885, 0.4478364807410696, 0.4535614828805928, 0.45420493352808927, 0.470649723832016, 0.49416438578527516, 0.42504766354131296, 0.4356196666543041, 0.4477375679364763, 0.45850170697990217, 0.4621103251356782, 0.45599875571627085, 0.44742088580901274, 0.45518131913686083, 0.3916728433415038, 0.45073289215686424, 0.4618718498393974, 0.46242390967339486, 0.44098508691850163, 0.448869055181272, 0.4460112398529878, 0.45686489464989805, 0.5170516463285189, 0.41261863131255444, 0.4269844670109108, 0.45063545242671416, 0.4576435387951397, 0.4654757197632899, 0.45435432921514923, 0.45561196861096553, 0.4302019586233661, 0.42467360628576506, 0.4443710724926053, 0.44996268307995985, 0.44855685178483395, 0.4317572844656661, 0.43865048859035993, 0.4384211607240616, 0.45372811849235783, 0.5479304546636626, 0.3951226743719468, 0.4252590835637448, 0.4559255199818461, 0.4589722080083003, 0.47157736617852214, 0.45626321571526823, 0.4627526970906395, 0.39554049385506745, 0.45895726406609083, 0.4387853668104117, 0.43624306484873904, 0.42899141021152337, 0.4115606120905675, 0.42142089294152585, 0.4259188826795958, 0.462438163290522, 0.5862909502862402, 0.36897075371758276, 0.4305340928094376, 0.4636214963033894, 0.46364111612478154, 0.4821250141875786, 0.46523956838263314, 0.45739273444298656, 0.34220879642955937, 0.5002262894848427, 0.43183328624373024, 0.41885180709319125, 0.4029668724691314, 0.38503164987332705, 0.3956338840407439, 0.3963837219407035, 0.46881451078458375, 0.6395942041073942, 0.3494046996484314, 0.4383094501528854, 0.469671916390269, 0.4691108177100982, 0.4915463985581852, 0.4787291659825238, 0.43149592398449566, 0.29474863587221334, 0.5699700402410314, 0.40251407005591483, 0.3963789620932276, 0.3795601470223311, 0.35492344917792207, 0.3598991930185775, 0.3398266606853395, 0.41861414056727964, 0.6594853939951005, 0.27962959499977813, 0.4461648312566046, 0.4706001066957555, 0.46971881037057933, 0.49024335261301166, 0.48942407392637227, 0.3684111492160382, 0.1888661181208507, 0.6876296104533333, 0.37976213584326507, 0.41940339570977875, 0.42320980517882384, 0.38598152902214616, 0.3832977209365965, 0.3613020866085187, 0.3949899010252512, 0.6392295481346739, 0.17362982955141565, 0.4488062432316435, 0.4620561268068854, 0.4609233596639275, 0.47477160179739947, 0.48211444308585333, 0.363531178515126, 0.10949931422589586, 0.8501424224649682]

    # partly optimized N 16
    global best_initial_params = [0.6220815844218643, 0.5074299332413689, 0.5043683661182545, 0.49833971476266936, 0.510276914590918, 0.5206618481136615, 0.4975782647149601, 0.4673260981676485, 0.27884217212428736, 0.7297506295350712, 0.4019230939082593, 0.40005357543076053, 0.39432360019260637, 0.40656362223991027, 0.39863791889482053, 0.5009165590556394, 0.5692065015544103, 0.8144953178237411, 0.19197236573785406, 0.5642210190079168, 0.514699058635048, 0.510063445337522, 0.507972422137101, 0.5213059927782336, 0.5341314691867797, 0.47675003527578846, 0.4098421040078092, 0.05333415697659525, 0.6371003796698035, 0.3667441475311083, 0.3690341430998577, 0.3662042658821537, 0.36559063901636046, 0.3519803186064862, 0.4285521039991945, 0.471115205954165, 0.6764690359416615, 0.040579283329537696, 0.486226060012143, 0.49018287915752984, 0.4957628417227415, 0.49083052765743207, 0.5034549719440377, 0.5092834284392466, 0.4480333758574123, 0.3932438110888484, 0.21648548778319043, 0.646349850250317, 0.36462528312560016, 0.36861915265885165, 0.36406137501143115, 0.35726763781652926, 0.34952502834386967, 0.3994587733312759, 0.4190320496289091, 0.7438492198596284, 0.2476704692153765, 0.43891428269000704, 0.4733558419031427, 0.4887712260308605, 0.4807146062323302, 0.48160653375027096, 0.481180211384564, 0.44008740789584044, 0.4061376708136198, 0.3739104997914293, 0.6341555407802265, 0.3889473048521571, 0.3893005009189968, 0.38417147102916255, 0.3768816276271518, 0.3830375722357215, 0.4151744966837484, 0.4270219758376815, 0.8416866117159194, 0.2694030955395506, 0.4196925205648892, 0.46988797141384475, 0.483897659166203, 0.479502535332453, 0.4668529190993664, 0.46707945263029155, 0.4617968438598367, 0.4499237689958424, 0.5169836346921121, 0.553008340733257, 0.4187009144354002, 0.41387036598396293, 0.4118604700949456, 0.40573176528037863, 0.4216980313106259, 0.43404576481595336, 0.43588026294986454, 0.706257850013514, 0.31480123084361944, 0.4275331145947237, 0.4680030360167914, 0.4808077690026382, 0.47746226091976474, 0.45862085291814475, 0.46666764260770316, 0.4879527631138068, 0.49473709138514743, 0.4791975331448968, 0.47993747512691676, 0.4402711922285741, 0.4329224591212818, 0.4362612953531481, 0.4317137621446912, 0.4483532145702137, 0.43913068425403984, 0.4331303951664044, 0.6111909120099835, 0.35357183552868354, 0.44358599995818765, 0.4666761392590883, 0.4814236631565478, 0.46930234730206644, 0.456265202927857, 0.4705020413543463, 0.4970796947765406, 0.5128492644240815, 0.4877025808223337, 0.4408574998763726, 0.4485646781633508, 0.4424284731792912, 0.4519302163059157, 0.44897535943583483, 0.45773191322969325, 0.439407054955082, 0.42738223841891093, 0.5399894500697368, 0.35692916680978237, 0.45645143889068157, 0.4672143863178301, 0.4784993767658723, 0.4570218221678604, 0.4552191893231975, 0.46530261811701246, 0.4873109174732874, 0.507382654087825, 0.4810899918524526, 0.429454572791997, 0.4453710382258717, 0.44534435642642245, 0.4582760252749315, 0.4579025740857742, 0.4583917194195282, 0.4422010816651988, 0.4299572473862286, 0.49172120406709846, 0.36828646203067217, 0.45644322736454057, 0.4673151023057377, 0.4712762664531882, 0.44783648074106963, 0.4535614828805924, 0.45420493352808927, 0.47064972383201575, 0.4892552918814488, 0.4946542232582009, 0.4250476635413133, 0.4356196666543041, 0.447737567936476, 0.45850170697990217, 0.46211032513567835, 0.45599875571627047, 0.4474208858090129, 0.4402067032312756, 0.45455305643700883, 0.39167284334150343, 0.45073289215686424, 0.4618718498393974, 0.4624239096733947, 0.44098508691850186, 0.44886905518127207, 0.4460112398529882, 0.45686489464989777, 0.4704406179825261, 0.5187086614056974, 0.41261863131255444, 0.4269844670109108, 0.4506354524267141, 0.45764353879513947, 0.4654757197632901, 0.45435432921514946, 0.45561196861096576, 0.44667465216470104, 0.41325055215791656, 0.42467360628576506, 0.4443710724926052, 0.44996268307995985, 0.44855685178483384, 0.4317572844656658, 0.43865048859035966, 0.4384211607240616, 0.45372811849235745, 0.4680796274613714, 0.5534793310291666, 0.3951226743719471, 0.4252590835637448, 0.45592551998184633, 0.45897220800830046, 0.47157736617852214, 0.456263215715268, 0.4627526970906395, 0.4473656917077607, 0.3683598214699904, 0.45895726406609066, 0.4387853668104117, 0.43624306484873904, 0.42899141021152337, 0.4115606120905678, 0.4214208929415261, 0.42591888267959604, 0.4624381632905215, 0.4820142952457422, 0.5968689522822472, 0.36897075371758314, 0.43053409280943783, 0.4636214963033894, 0.4636411161247812, 0.48212501418757836, 0.465239568382633, 0.45739273444298684, 0.43527935562644976, 0.3143134915198894, 0.5002262894848427, 0.43183328624373024, 0.4188518070931909, 0.40296687246913154, 0.3850316498733267, 0.3956338840407444, 0.3963837219407036, 0.46881451078458364, 0.4986941886189545, 0.6458574151620945, 0.3494046996484314, 0.43830945015288564, 0.4696719163902688, 0.4691108177100984, 0.4915463985581852, 0.478729165982524, 0.43149592398449593, 0.4046009433327422, 0.2572832756976805, 0.5699700402410314, 0.40251407005591483, 0.3963789620932271, 0.37956014702233143, 0.35492344917792223, 0.3598991930185775, 0.3398266606853397, 0.4186141405672796, 0.45209523277266817, 0.6738337280741176, 0.27962959499977785, 0.446164831256605, 0.4706001066957555, 0.46971881037057955, 0.4902433526130114, 0.48942407392637227, 0.3684111492160382, 0.32933914038752377, 0.16674677393473325, 0.6876296104533327, 0.37976213584326507, 0.41940339570977875, 0.4232098051788239, 0.38598152902214616, 0.3832977209365965, 0.36130208660851837, 0.3949899010252514, 0.4120325585849793, 0.6571339147068285, 0.17362982955141582, 0.4488062432316437, 0.4620561268068854, 0.46092335966392733, 0.47477160179739974, 0.48211444308585283, 0.363531178515126, 0.30943876393793757, 0.08690522889335826, 0.850142422464969]

    # partly optimized N 18
    #global best_initial_params =

     # average
    # best parameter n12
    #global best_initial_params = [0.6691170700329109, 0.5242419499398641, 0.5219950418466577, 0.5344866264870451, 0.5555275048144922, 0.5459614663519656, 0.33758304418559015, 0.7405336821996115, 0.4036627725871211, 0.3904559136249411, 0.3987365764464238, 0.37220207555475626, 0.48841104360781173, 0.7451454874620587, 0.1906040496316695, 0.6107622836707435, 0.5383683207672475, 0.53159829467978, 0.5475637506677792, 0.5512769072913675, 0.513590236445991, 0.12771296408549299, 0.6204954308186355, 0.3665093198649766, 0.352132701825671, 0.3469364143217169, 0.319106701054995, 0.4131661725280238, 0.7020445356521505, 0.02801912150665006, 0.5030864893667775, 0.5250553797247837, 0.5175947964931998, 0.5216257922867277, 0.5111994300870015, 0.47962034757649286, 0.22842316594180034, 0.6624283106999874, 0.3560538790016715, 0.34920757520557477, 0.3364536504004578, 0.34032832570057603, 0.3936000614439802, 0.6645413455736382, 0.2557549271801634, 0.4560441417006819, 0.5191728368454721, 0.5105161827394992, 0.5029715286118254, 0.49340022849153575, 0.4873516163317549, 0.398337157714468, 0.6417645960563051, 0.37454169122466807, 0.37397203124812195, 0.3645916834241772, 0.383252607174849, 0.40405507837290144, 0.6855183640197124, 0.25289438551848803, 0.4422170004269503, 0.5164056966744396, 0.504697918832754, 0.49278019840325976, 0.4821205790630709, 0.5049947185556202, 0.5151716254839237, 0.564022969286816, 0.4079136002265289, 0.4075347229229323, 0.40561038520480514, 0.4182048550688855, 0.42457398541039054, 0.5967756261230922, 0.30293824305246964, 0.4469058592886743, 0.5116429202248637, 0.49438047820355285, 0.4838334997341326, 0.4757537743197707, 0.5160959078103142, 0.5161726890636571, 0.5160601100762315, 0.4382011452129241, 0.4356646742203481, 0.4394840558371078, 0.44112971250839245, 0.44739351633831087, 0.5368139732084175, 0.3413832319623705, 0.46556956486050166, 0.5074615595885544, 0.48355948904796925, 0.4776548076927032, 0.4716012367624861, 0.5136034615710238, 0.5073242958040228, 0.49210437875171964, 0.45465329493597495, 0.4514031858767302, 0.45801392228036053, 0.4472896938626881, 0.4603225771350285, 0.5079064028954043, 0.36733651920459287, 0.47450510364533705, 0.5035526574748966, 0.47369735972308485, 0.4716936254807815, 0.4629693640065968, 0.49613468933233146, 0.5098141868933729, 0.4798685198662794, 0.45688961819013035, 0.4570528026372785, 0.463781849473797, 0.44601517815851827, 0.46948218924949686, 0.4902560991860006, 0.39391446850468326, 0.47220464559472225, 0.4971346271111322, 0.46351581585143703, 0.4640176085193582, 0.4530156188914939, 0.47870418113086927, 0.5175130831879625, 0.4663777078716383, 0.45053736558239416, 0.45848391028710717, 0.4658254025178579, 0.4480512224048432, 0.4728963175659196, 0.4717881072253287, 0.42549110966171816, 0.46712482523039767, 0.4842503037596801, 0.4546279039176067, 0.45526158826023466, 0.4447969438543348, 0.46582207848496293, 0.5285936297012741, 0.4369283691845633, 0.4436330003735385, 0.4618598624162408, 0.47269112895637927, 0.452620266296359, 0.47415593979589765, 0.44313797792816856, 0.4576660975639134, 0.46619793726799247, 0.4605040767195494, 0.4410412582567267, 0.44248997354030645, 0.4302995278153553, 0.4552662764207914, 0.5394386493316419, 0.4041332944642591, 0.4422160791499153, 0.47044782497845233, 0.48886458409911354, 0.46265388586008, 0.47068142567577104, 0.4019685554429275, 0.4881049077052068, 0.4654177628364071, 0.4305283253182997, 0.416848614740931, 0.4185574805415373, 0.4046550623761979, 0.4557874378805631, 0.5644773809885576, 0.36980365297481943, 0.44647681684832924, 0.4832583709572518, 0.5106940149905265, 0.4847828027246752, 0.46454183420233486, 0.3501639426885731, 0.527175669101304, 0.4514486282744368, 0.39528003387102706, 0.3849024251421154, 0.3787396707593207, 0.3663878483622623, 0.45788045661818016, 0.6138232674718566, 0.34781477117095877, 0.45311523453123165, 0.4934289124880065, 0.5276282213108965, 0.5089702502048445, 0.44794461039869715, 0.30671520392820956, 0.5981449368225052, 0.4067841518073535, 0.36247374054512727, 0.3439347070641368, 0.33005255558439556, 0.3057511893876769, 0.3988102000710281, 0.639643637728671, 0.27943709446266396, 0.4574006245702813, 0.4942658585371879, 0.5266576225221798, 0.5189551235855562, 0.38847500820500613, 0.2029341182115111, 0.7320176365781351, 0.39272193481469914, 0.4180173465816134, 0.4018404315932081, 0.36832644417919547, 0.33664609141038343, 0.3726852270931236, 0.6056771242922551, 0.1602917123442874, 0.45384146033546807, 0.4801094958417286, 0.49906675962779223, 0.502322134431305, 0.36483925474101786, 0.11190028696289961, 0.9161741335505841]


    # N 10  optimized
    #global best_initial_params = [0.6691170700329109, 0.5242419499398641, 0.5219950418466577, 0.5344866264870451, 0.5555275048144922, 0.5459614663519656, 0.33758304418559015, 0.7405336821996115, 0.4036627725871211, 0.3904559136249411, 0.3987365764464238, 0.37220207555475626, 0.48841104360781173, 0.7451454874620587, 0.1906040496316695, 0.6107622836707435, 0.5383683207672475, 0.53159829467978, 0.5475637506677792, 0.5512769072913675, 0.513590236445991, 0.12771296408549299, 0.6204954308186355, 0.3665093198649766, 0.352132701825671, 0.3469364143217169, 0.319106701054995, 0.4131661725280238, 0.7020445356521505, 0.02801912150665006, 0.5030864893667775, 0.5250553797247837, 0.5175947964931998, 0.5216257922867277, 0.5111994300870015, 0.47962034757649286, 0.22842316594180034, 0.6624283106999874, 0.3560538790016715, 0.34920757520557477, 0.3364536504004578, 0.34032832570057603, 0.3936000614439802, 0.6645413455736382, 0.2557549271801634, 0.4560441417006819, 0.5191728368454721, 0.5105161827394992, 0.5029715286118254, 0.49340022849153575, 0.4873516163317549, 0.398337157714468, 0.6417645960563051, 0.37454169122466807, 0.37397203124812195, 0.3645916834241772, 0.383252607174849, 0.40405507837290144, 0.6855183640197124, 0.25289438551848803, 0.4422170004269503, 0.5164056966744396, 0.504697918832754, 0.49278019840325976, 0.4821205790630709, 0.5049947185556202, 0.5151716254839237, 0.564022969286816, 0.4079136002265289, 0.4075347229229323, 0.40561038520480514, 0.4182048550688855, 0.42457398541039054, 0.5967756261230922, 0.30293824305246964, 0.4469058592886743, 0.5116429202248637, 0.49438047820355285, 0.4838334997341326, 0.4757537743197707, 0.5160959078103142, 0.5161726890636571, 0.5160601100762315, 0.4382011452129241, 0.4356646742203481, 0.4394840558371078, 0.44112971250839245, 0.44739351633831087, 0.5368139732084175, 0.3413832319623705, 0.46556956486050166, 0.5074615595885544, 0.48355948904796925, 0.4776548076927032, 0.4716012367624861, 0.5136034615710238, 0.5073242958040228, 0.49210437875171964, 0.45465329493597495, 0.4514031858767302, 0.45801392228036053, 0.4472896938626881, 0.4603225771350285, 0.5079064028954043, 0.36733651920459287, 0.47450510364533705, 0.5035526574748966, 0.47369735972308485, 0.4716936254807815, 0.4629693640065968, 0.49613468933233146, 0.5098141868933729, 0.4798685198662794, 0.45688961819013035, 0.4570528026372785, 0.463781849473797, 0.44601517815851827, 0.46948218924949686, 0.4902560991860006, 0.39391446850468326, 0.47220464559472225, 0.4971346271111322, 0.46351581585143703, 0.4640176085193582, 0.4530156188914939, 0.47870418113086927, 0.5175130831879625, 0.4663777078716383, 0.45053736558239416, 0.45848391028710717, 0.4658254025178579, 0.4480512224048432, 0.4728963175659196, 0.4717881072253287, 0.42549110966171816, 0.46712482523039767, 0.4842503037596801, 0.4546279039176067, 0.45526158826023466, 0.4447969438543348, 0.46582207848496293, 0.5285936297012741, 0.4369283691845633, 0.4436330003735385, 0.4618598624162408, 0.47269112895637927, 0.452620266296359, 0.47415593979589765, 0.44313797792816856, 0.4576660975639134, 0.46619793726799247, 0.4605040767195494, 0.4410412582567267, 0.44248997354030645, 0.4302995278153553, 0.4552662764207914, 0.5394386493316419, 0.4041332944642591, 0.4422160791499153, 0.47044782497845233, 0.48886458409911354, 0.46265388586008, 0.47068142567577104, 0.4019685554429275, 0.4881049077052068, 0.4654177628364071, 0.4305283253182997, 0.416848614740931, 0.4185574805415373, 0.4046550623761979, 0.4557874378805631, 0.5644773809885576, 0.36980365297481943, 0.44647681684832924, 0.4832583709572518, 0.5106940149905265, 0.4847828027246752, 0.46454183420233486, 0.3501639426885731, 0.527175669101304, 0.4514486282744368, 0.39528003387102706, 0.3849024251421154, 0.3787396707593207, 0.3663878483622623, 0.45788045661818016, 0.6138232674718566, 0.34781477117095877, 0.45311523453123165, 0.4934289124880065, 0.5276282213108965, 0.5089702502048445, 0.44794461039869715, 0.30671520392820956, 0.5981449368225052, 0.4067841518073535, 0.36247374054512727, 0.3439347070641368, 0.33005255558439556, 0.3057511893876769, 0.3988102000710281, 0.639643637728671, 0.27943709446266396, 0.4574006245702813, 0.4942658585371879, 0.5266576225221798, 0.5189551235855562, 0.38847500820500613, 0.2029341182115111, 0.7320176365781351, 0.39272193481469914, 0.4180173465816134, 0.4018404315932081, 0.36832644417919547, 0.33664609141038343, 0.3726852270931236, 0.6056771242922551, 0.1602917123442874, 0.45384146033546807, 0.4801094958417286, 0.49906675962779223, 0.502322134431305, 0.36483925474101786, 0.11190028696289961, 0.9161741335505841]


    """
    # for higher N
    initial_params_n = expand_blocks_v2(best_initial_params, Int(N-2))

    global best_initial_params = copy(initial_params_n)
    #println(best_initial_params)
    #println(size(best_initial_params))
    
    
    # for lower N
    initial_params_n = reduce_blocks_v2(best_initial_params, N)

    global best_initial_params = copy(initial_params_n)
    #println(best_initial_params)
    #println(size(best_initial_params))
    """
#############################
    
"""
    add_params = zeros(2)
    n_iter_p1 = 5
    n_iter_p2 = 5

    max_p1 = 0.8
    min_p1 = 0.3
    max_p2 = 0.8
    min_p2 = 0.3


    for i in 1: n_iter_p1

        p1 = (min_p1 + (i-1)*(max_p1-min_p1)/n_iter_p1)
        p1 = round(p1, digits=1)
        for j in 1: n_iter_p2

            p2 = (min_p2 + (j-1)*(max_p2-min_p2)/n_iter_p2)
            p2 = round(p2, digits=1)
            add_params_local = vcat(p1, p2)
            println(add_params_local)
            initial_params = expand_blocks_2(best_initial_params, add_params_local, N-2)
            #println(initial_params)
            cost, params, probs = optimize_parameters_half(MAX_problem, initial_params, niter=niter, learning_rate=learning_rate)
            println(cost)
            if abs(cost) > abs(best_cost)
                global best_cost = cost
                global best_params = params
                global _params = initial_params
                add_params = add_params_local
                #global best_probs = probs
            end

        end

    end

    println(add_params)
    print(best_cost)

#############################

    global best_initial_params = replace_blocks_v2(_params, best_params, N)
"""

#############################

    """
    #cost, params, probs = optimize_parameters_half(MAX_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
    cost, params, probs = optimize_parameters_two_v2(MAX_problem, best_initial_params, niter=niter, learning_rate=learning_rate)

    #println(cost)
    #println(params)


    #global best_initial_params = replace_blocks_v2(best_initial_params, params, N)
    

    niter = 100  
    global learning_rate = 0.001  #N16 0.001 #N14 0.005
    
    
    for j in 1:2

        cost, params, probs = optimize_parameters_two_v2(MAX_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        #println("x")
        #println(params)
        if abs(cost) > abs(best_cost)
            global best_cost = cost
            global best_params = params
            #global best_initial_params = initial_params
            global best_lr = learning_rate
            global best_probs = probs
        else
            break
        end

        global learning_rate += 0.004 #N16 0.004 #N14 0.01

    end
    
    
    """
    # one big increase step for learning rate
    global learning_rate = 0.1
    niter = 0
    
    cost, params, probs = optimize_parameters_two_v2(MAX_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        
    if abs(cost) > abs(best_cost)
        global best_cost = cost
        global best_params = params
        #global best_initial_params = initial_params
        global best_lr = learning_rate
        global best_probs = probs
    end
    

    ### using final optimized parameter without sperate optimization process for each instance



    println("Optimal cost: ", best_cost)
    println("Optimal initial parameter: ", best_initial_params[1])
    println("Optimal parameter: ", best_params[1:33])
    println(best_lr)

    
    # save the optimal parameters and cost

    PATH_w = raw"/home/ubuntu/aqc_VQE"


    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n10_parameter_opt_data//", N, p);
    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n10_parameter_test_data//", N, p);
    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n10_raw_parameter_test_data//", N, p);
    

    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n14_parameter_opt_data//", N, p);
    folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n14_parameter_test_data//", N, p);
    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n14_raw_parameter_test_data//", N, p);

    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n12_parameter_opt_data//", N, p);
    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n12_parameter_test_data//", N, p);
    #folder_name_w = PATH_w * @sprintf("//vqe_v2_MAX2SAT_data//N_%i//p%i//n12_raw_parameter_test_data//", N, p);



    h5open(folder_name_w * @sprintf("optimized_MAX2SAT_instance_N_%i_idx_%04i.h5", N, idx), "w") do file
        write(file, "ground_state_energy", gs_energy)           
        write(file, "idx", idx)                               # Save seed
        write(file, "cost_value", best_cost)                    # Save cost values
        write(file, "parameter_angles", best_params)            # Save parameters
        write(file, "initial_parameters", best_initial_params)  # Save initial parameters
        write(file, "learning_rate", best_lr)                   # Save learning rate
        write(file, "probabilities", best_probs)                # Save probs
    end
        
end 

println("============================================================ N = ", N, ", ", total_num_inst," instances, done! ============================================================")
