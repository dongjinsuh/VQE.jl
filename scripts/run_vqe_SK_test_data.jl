using HDF5 
using Printf
using LinearAlgebra
using DataFrames
import Random, Distributions

using VQE
using Zygote
using PyPlot
using Parameters
using NLopt
using DocStringExtensions
using OrdinaryDiffEq
#using Yao
using YaoBlocks, ChainRulesCore


# load the SK hard instance data

N = 14
#N = parse(Int, ARGS[1])

PATH = raw"/home/ubuntu/aqc_QAOA/SpinFluctuations.jl"
#PATH = raw"/home/ubuntu/aqc_QAOA"


#subdir = "small_gaps"
# subdir = "large_gaps"

# original data
folder_name = PATH * @sprintf("//data//N_%i//", N);

# transformation test data
#folder_name = PATH * @sprintf("//transformation_hard_SK_instances//transformation_test_data//N_%i//", N);

# permutation test data
#folder_name = PATH * @sprintf("//transformation_hard_SK_instances//permutation_test_data//N_%i//", N);

###

### change N in the pattern individually 
#pattern = r"transformed_hard_SK_instance_N_12_seed_(\d+)\.h5"

# original data
pattern = r"hard_random_SK_instance_N_12_seed_(\d+)\.h5"

###

instance_names = readdir(folder_name)
loop_var = 1
#loop_var = parse(Int, ARGS[2])
total_num_inst = 0

#0-200 permutation
#0-100 transformation
#1000-1100 original
for (k, instance_name) in enumerate(instance_names[loop_var+1000:loop_var+1200])

    global total_num_inst = k
    println("current instance count: ", k)

    seed = match(pattern, instance_name)[1]
    seed = parse(Int64, seed)
    #seed = 124810
    println("seed: ", seed)
    #spin_idx = 2

    file_name = folder_name * @sprintf("hard_random_SK_instance_N_%i_seed_%i.h5", N , seed)
    #file_name = folder_name * @sprintf("transformed_hard_SK_instance_N_%i_seed_%i.h5", N , seed)

    gs_energy = h5read(file_name, "ground_state_energy") 
    J_mat = h5read(file_name, "couplings"); 
    local_fields = h5read(file_name, "local_fields")
    mf_problem = Problem(0, local_fields, J_mat);
    println(gs_energy)

    p = 5

    SK_problem = Problem(p, local_fields, J_mat)

    #circ = VQE.circuit(SK_problem)
    #num_params = VQE.nparameters(circ)
    num_params = (2*N+1)*p

    global learning_rate = 0.00005   
    niter = 100

    global best_cost = 0
    global best_params = zeros(num_params)
    global best_initial_params = zeros(num_params)
    global best_lr = learning_rate
    global best_probs = zeros(Float64, 2^N)

     # average

    global best_initial_params = [0.6390877480860438, 0.6224866255315168, 0.602938634381911, 0.6323625352098211, 0.6731964355471481, 0.6334545340950863, 0.6634080408075632, 0.6432451524013939, 0.6834951853535883, 0.6444704052712127, 0.710831160280054, 0.6605972809621211, 0.3152326491155327, 0.3074071461915337, 0.28446687796967796, 0.28146275510342783, 0.29497986162765366, 0.29150522608631463, 0.28037959376746086, 0.3046320257894916, 0.26431661506708054, 0.2707226487094296, 0.32023312592071124, 0.3044956100213693, 0.24177864939337215, 0.6270917980723815, 0.6205053682706257, 0.6001659169207743, 0.6490225915149859, 0.6117317329136389, 0.6185844427975785, 0.6381583880104843, 0.5943395288893704, 0.6354221514205355, 0.6517616885856813, 0.6380901666041415, 0.6159602398582003, 0.29597358639413834, 0.2843990921737236, 0.27555331609541195, 0.2776947859501359, 0.2851896255002372, 0.274806589563551, 0.26484519619817615, 0.2875809075122922, 0.25035831326161634, 0.2517642137813675, 0.266148837457925, 0.24638399045148698, 0.1924333746985699, 0.5851017530213087, 0.5860951344419241, 0.5872361290013325, 0.638696794338721, 0.6081857976687904, 0.6316109191454874, 0.6659325119328348, 0.608370490582136, 0.6692026152625163, 0.6825667592360887, 0.6657904140984718, 0.5796908993642204, 0.3218650440950435, 0.29172213979988587, 0.2880040471187941, 0.30280077606152694, 0.29655196738235046, 0.2883504919780603, 0.28199771364029086, 0.29925600551995013, 0.2731818586971923, 0.27285446442097555, 0.2619966711903184, 0.2644572167761156, 0.4650322529528558, 0.4698365927129524, 0.4722344520706019, 0.46503870417110676, 0.5076792825908767, 0.5386377593624214, 0.5127562799713279, 0.5416610034703891, 0.48454067794709793, 0.5403432753978787, 0.5556347323406665, 0.5030634226188204, 0.42961991733939825, 0.36934039049011513, 0.3162517953871683, 0.31636593794507295, 0.34219563042237466, 0.3219505126326446, 0.3255965148244602, 0.32264129200184355, 0.32734302269920906, 0.3181027811848382, 0.3246812721282301, 0.30063645395195304, 0.3233758125820299, 0.5622241512054089, 0.3532726849726925, 0.3668183166566528, 0.3598303146761126, 0.3706629514552937, 0.34046837113826145, 0.3305136855429566, 0.33806400060721825, 0.2674907339940056, 0.28730734688243686, 0.29865693286156936, 0.24930267471884449, 0.192358643564729, 0.36876349945905734, 0.32394094338513313, 0.32443676236819985, 0.3392809874076833, 0.32436041232976837, 0.3323742141277297, 0.3285914255978471, 0.32273045888974916, 0.3257467640986078, 0.3367447589537588, 0.31169688324378414, 0.31430108543510094, 0.7391408604257177]
    
    #global best_initial_params = [0.0777144506549288, 0.07736041191331446, 0.07725818720156055, 0.07796636966263729, 0.080948900722415, 0.07831912709001869, 0.08102224798744186, 0.0841419421203871, 0.08370272843223722, 0.08446235811141475, 0.08955925050359215, 0.09057391717967783, 0.049022021117024486, 0.05011572700379814, 0.04837199896462628, 0.049091971850007805, 0.04938824957827983, 0.05033836544554603, 0.0474557782678086, 0.04825839321635332, 0.04852248955855116, 0.04550278879086925, 0.04467053725500496, 0.045286293078589064, 0.1260136084748805, 0.08262870012410194, 0.08214020165128709, 0.08157544937536385, 0.08211963713075147, 0.08552402588793227, 0.08369407719625394, 0.08562434987330324, 0.08865531360968988, 0.08864831695863626, 0.08893504329956983, 0.09293282224571271, 0.09451075091949697, 0.046387397044286086, 0.04813632421115672, 0.04785785105741971, 0.04793058784786218, 0.04764174471209841, 0.04767981906147599, 0.04648213819389769, 0.045174687476266476, 0.04609207319211596, 0.04362394198706862, 0.044210742885479964, 0.04223481644702146, 0.056307014210272774, 0.08446767460156425, 0.08389563745877035, 0.08334862019651601, 0.08372538415851635, 0.08725943468499026, 0.08585246000392169, 0.08724958725231048, 0.08996373653455406, 0.08996959831765083, 0.09006937112627349, 0.09339256628855938, 0.09505473502228903, 0.044993819204338474, 0.04694683652949885, 0.04756890491712061, 0.04725503124392326, 0.04662510422702047, 0.0461110172607692, 0.0461033073144918, 0.04387266799168089, 0.04491426581363171, 0.0430767480803053, 0.04441162289329699, 0.0413332098157778, 0.03877919950140877, 0.08467179964108787, 0.08437215026523082, 0.08407215706338114, 0.08433665330921856, 0.08764065917682708, 0.08644308299900456, 0.08750283974078114, 0.0892482839353213, 0.08959202386512455, 0.08957643813187001, 0.09215590224195236, 0.09353525070946149, 0.04480338451023903, 0.046511700116944464, 0.047488778111025684, 0.047040019812072065, 0.04631937924633943, 0.045630303733515745, 0.04624818649213023, 0.04401164540525752, 0.04486406950830254, 0.04366311278389827, 0.04516447109759058, 0.042094581596069346, 0.030546184704686598, 0.08337237736026215, 0.08401028009272661, 0.08418395188517067, 0.08441599174489092, 0.08692425627521354, 0.08577426973818328, 0.0867605289453882, 0.08652930880909743, 0.08782230774524274, 0.087637297709361, 0.08913719475153338, 0.08971015396645059, 0.045816688166628136, 0.046847943918611516, 0.0476235884702787, 0.0472893546878423, 0.046754446511970554, 0.046254295449517605, 0.046889946890538464, 0.045488017266001976, 0.0458987708526032, 0.045329030714050325, 0.04640199572529509, 0.04441985266380017, 0.02842918508845982]
    
    #global best_initial_params = [0.25747975473550505, 0.2663971186658139, 0.26625088170022404, 0.28034328083736065, 0.284115562714581, 0.2869561624737701, 0.2930940885462805, 0.30142336645460427, 0.31118744993316255, 0.31118819896822175, 0.33411162206903794, 0.340976468717524, 0.08821163031088372, 0.09793334853945977, 0.0847489397790871, 0.07931496439810816, 0.0800039831085467, 0.0750447697071651, 0.06897017008984059, 0.07715514415046276, 0.07142699513228251, 0.07293310469522468, 0.08237348120507644, 0.0779362936846755, 0.13795959199260113, 0.23865285827091282, 0.24637623112182885, 0.2411480752766935, 0.24856810503298885, 0.2510826780440921, 0.2542624098806404, 0.255841195196273, 0.25892460682461643, 0.26472489416766415, 0.27070496884528467, 0.275279561705465, 0.26428121688866374, 0.07052809145264488, 0.07666129401199576, 0.07095170362403688, 0.0642239789048417, 0.06484694425586465, 0.062414259555464466, 0.05797704409672907, 0.060399489158844036, 0.058320222573243305, 0.05626105245450295, 0.061720984966728315, 0.054201685698528686, 0.03895520163224566, 0.21445982342999684, 0.22145428903488906, 0.21913986690760934, 0.22628512741213377, 0.22736181980166517, 0.233021348553764, 0.23465510431660713, 0.2378303072667984, 0.24413009507000266, 0.24663486765486733, 0.2460808974533781, 0.22992930801579137, 0.06116143859777844, 0.06506990768725113, 0.062008590101856706, 0.05789383542699219, 0.05641754127721235, 0.055624214866730644, 0.05275658499501871, 0.05147596350153238, 0.05248382802498983, 0.0493536150475694, 0.05223232078785072, 0.045161920556577057, 0.09293147843330785, 0.20306958004666978, 0.21092806750129905, 0.20572104165818497, 0.21501296254617247, 0.22221155211681465, 0.2194055181838421, 0.22894072687196593, 0.23006883765640104, 0.23310370005292488, 0.2325516132619708, 0.23404648142928608, 0.2236351611544626, 0.056955818858421964, 0.059830248177784144, 0.0568682515317637, 0.055523419561567686, 0.052813326683979075, 0.052921061091666846, 0.051266275292105055, 0.04881399108005752, 0.05125480343305589, 0.04929662754236779, 0.05073653250010195, 0.04610914938861406, 0.12479625479076478, 0.2075853127088685, 0.2154070636595754, 0.21150109196173442, 0.21862490235871335, 0.21641769884555248, 0.21749878561901548, 0.2120184178880385, 0.20839742419028526, 0.2032041986930195, 0.20196924814969264, 0.1938911027350881, 0.1754707206232136, 0.05411349875214318, 0.05659084498318255, 0.0535317163527791, 0.054637139960454675, 0.051811055710074466, 0.051602464182259826, 0.05121164514334985, 0.049307199342592756, 0.05116404596585008, 0.051686426512962125, 0.05215664395383277, 0.04926586171990723, 0.19804056797268718]

    #global best_initial_params = [1.2403756164896742, 1.200552515108357, 1.229126587305923, 1.1960056777972956, 1.2004450868737906, 1.1816336697280232, 1.1496206461755152, 1.1284350787190904, 1.1585603746077664, 1.1426538699086164, 1.1469321449969236, 1.086178718404342, 0.6906498849210927, 0.7062456691972006, 0.6715642455823619, 0.7109723662686067, 0.7788256149190279, 0.706579459068211, 0.7473597753917851, 0.7170030249935944, 0.7473702093528484, 0.73321833687789, 0.8273918354429368, 0.7954583325179757, 0.5490660028975943, 0.9598107065357057, 0.9399935299346939, 0.953025161500007, 0.9214660062406153, 0.9279029821003416, 0.9303033468380356, 0.9320161695041019, 0.89480598714465, 0.9171185625766358, 0.9131818285591636, 0.8705958809532176, 0.7729457674691286, 0.6909803791388267, 0.6712689306198157, 0.676993162058294, 0.7490485201123407, 0.7827819951777512, 0.6832842277978786, 0.7535648199013674, 0.7270459443384895, 0.7201626494002179, 0.7197842692555535, 0.775349401117793, 0.6940706890051483, 1.0057209079994494, 0.827521380735663, 0.8226842062733544, 0.7976794565744676, 0.7750116667206648, 0.7902427246071615, 0.7814119093755577, 0.7798173915392451, 0.7500056648105252, 0.7567066888804028, 0.7412741425110799, 0.6971616397045077, 0.6154748693132837, 0.838395321540161, 0.7966119742434362, 0.8052876790170543, 0.8986078795298132, 0.8840682001645691, 0.8045356438091259, 0.8430848732821801, 0.8560609565307543, 0.8471917999113671, 0.8348492350107628, 0.860413053367208, 0.8089014682352041, 1.1181363943849711, 0.5945418887740639, 0.56794400868932, 0.573373263731868, 0.56960794630063, 0.5828593941502245, 0.5749312452953994, 0.5930200646483482, 0.5654360002020657, 0.580100925107364, 0.5528100608084819, 0.5140608247509454, 0.432851025961937, 0.9255604079049582, 0.8883544595120552, 0.8769009583299935, 0.9444777828644239, 0.9301756741482533, 0.8893449737031037, 0.9031437378303344, 0.9164216749759977, 0.9173432480385562, 0.8826163135665, 0.9008900697796138, 0.868988151989974, 1.2984912796304144, 0.45006504123262747, 0.4508482851023334, 0.42027570701686395, 0.4082648802055969, 0.38060308542795895, 0.33850933614854745, 0.34221765548038924, 0.3053994010178091, 0.2991225199370501, 0.2556052042908094, 0.22913923696530386, 0.1776219081424008, 0.9107992936392966, 0.895122715182479, 0.8744019897906887, 0.9004801332109083, 0.9016784054547197, 0.8812947230242053, 0.8922435156890579, 0.8843446119579171, 0.8921446233896622, 0.8618935185328161, 0.8636609044782351, 0.815825212623902, 1.5828405455943115]

    """
    
    global learning_rate = 0.0001

    #cost, params, probs = optimize_parameters_mix(SK_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
    
    for j in 1:2
        
        cost, params, probs = optimize_parameters_mix(SK_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        
        if abs(cost) > abs(best_cost)
            global best_cost = cost
            global best_params = params
            #global best_initial_params = initial_params
            global best_lr = learning_rate
            global best_probs = probs
        else
            break
        end

        global learning_rate += 0.002

    end

    for i in 1:4

        cost, params, probs = optimize_parameters_mix(SK_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        
        if abs(cost) > abs(best_cost)
            global best_cost = cost
            global best_params = params
            #global best_initial_params = initial_params
            global best_lr = learning_rate
            global best_probs = probs
        else
            break
        end

        global learning_rate += 0.01

    end
    
    # one big increase step for learning rate
    #global learning_rate = 0.1
    niter = 0
    cost, params, probs = optimize_parameters_mix(SK_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        
    if abs(cost) > abs(best_cost)
        global best_cost = cost
        global best_params = params
        #global best_initial_params = initial_params
        global best_lr = learning_rate
        global best_probs = probs
    end
    """

    ### using final optimized parameter without sperate optimization process for each instance
    niter = 0
    cost, params, probs = optimize_parameters_mix(SK_problem, best_initial_params, niter=niter, learning_rate=learning_rate)
        
    global best_cost = cost
    global best_params = params
    #global best_initial_params = initial_params
    global best_lr = learning_rate
    global best_probs = probs


    println("Optimal cost: ", best_cost)
    println("Optimal initial parameter: ", best_initial_params[1])
    println("Optimal parameter: ", best_params[1:10])
    #println(best_lr)

    
    # save the optimal parameters and cost

    PATH_w = raw"/home/ubuntu/aqc_VQE"

    #folder_name_w = PATH_w * @sprintf("//vqe_mix_SK_data//trans_data//N_12//p5//final_parameter_test_data_fix//");

    #folder_name_w = PATH_w * @sprintf("//vqe_mix_SK_data//perm_data//N_12//p5//final_parameter_test_data//");
    
    folder_name_w = PATH_w * @sprintf("//vqe_mix_SK_data//origin_data//N_12//p5//sec_final_parameter_test_data//");


    h5open(folder_name_w * @sprintf("optimized_hard_SK_instance_N_%i_seed_%i.h5", N, seed), "w") do file
        write(file, "ground_state_energy", gs_energy)           
        write(file, "seed", seed)                               # Save seed
        write(file, "cost_value", best_cost)                    # Save cost values
        write(file, "parameter_angles", best_params)            # Save parameters
        write(file, "initial_parameters", best_initial_params)  # Save initial parameters
        write(file, "learning_rate", best_lr)                   # Save learning rate
        write(file, "probabilities", best_probs)                # Save probs
    end
        
end 

println("============================================================ N = ", N, ", ", total_num_inst," instances, done! ============================================================")
